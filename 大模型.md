作者：Rooters
链接：https://zhuanlan.zhihu.com/p/657826357
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

一些比较高频的东西（针对基座算法/框架岗位为主，大体按重要性排序）：
* 1.多头注意力，频率太高了。coding轮，概念轮都考。复习的点包括：时间/空间复杂度，优化（kv-cache，MQA，GQA），手写多头代码。各种Norm，这个频率也不低，不过比较标准的内容，没有啥特意要说的，有的考手写，有的考概念和理解（为什么管用）。
* 2. 框架相关内容，各种并行方式，优缺点。DeepSpeed，Megatron可以看看源代码，Flash-Attention等内容。这个点也经常考代码题。
*  3.  BERT，GPT等比较主流大模型，一些细节，比如位置编码，训练loss，激活，架构些许不同这种。自回归重点。
*  4.  大模型训练，这个可能主要是工作经验相关，经常问比如训练loss炸掉了，如何解决，一些技巧之类的。面试时有些面试官会问一些很细节的东西，感觉是在确认确实上手跑过基座训练不是吹水。
*  5.  数据预处理，BPE，tokenization，mask相关概念和对模型/训练影响，数据配比（有paper）。
*  6.  evaluation，如何评估大模型，安全性，有效性，公开数据，个别考过手写eval框架（多选，生成）。
*  7. 根据投的岗位，多模态和RLHF内容可以适当看看。这俩感觉paper挺重要的，也大多研究岗位。楼主也少面了一些自动驾驶，RL啥的，不过结果不咋地。
*  PS：有些非基座相关的或者实在没啥印象的就没写。还有几家背景和面试感觉特别好的公司，不过猎头特别说了要保密，不方便发，如果有朋友想了解的话可私信。
